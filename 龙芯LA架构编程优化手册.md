# 龙芯LA架构编程调优手册

## 1. 多核编程




## 2. SIMD编程

* SIMD编程模型，介绍了使用LA的SIMD指令进行编程的一些基本规则。

* SIMD编程实践，用两个实例来进一步说明SIMD编程方法。

### 2.1 SIMD编程模型

参考：龙芯LA架构手册卷二。

**寄存器**  
LA指令集第一版就包含了128和256位的向量扩展，2号处理器支持128位的 LSX；3号处理器支持128位的 LSX 和256位的 LASX。可以直接对标X86的SSE4和AVX2，以及ARM的NEON和AArch64。  

![image-20230904155011851](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/2-simd-x86-arm.png?raw=true)

![image-20230904155101617](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/3-la-register-detail.png?raw=true)

通用寄存器      ：32个，64位，$r0~$r31  
浮点寄存器      ：32个，64位，$f0~$f31  
向量寄存器      ：32个，128位，$v0~$v1  
扩展向量寄存器   ：32个，256位，$x0~$x1  

![image-20230904154926060](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/1-register.png?raw=true)

**数据类型**  
SIMD指令支持多种数据类型，每个向量寄存器可存储一组 B/H/W/D/S 类型元素，每个指令的命名直接体现改指令所处理的数据类型，如下图所示。

![image-20230904155150227](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/4-la-simd-data-type.png?raw=true)

**指令**  
SIMD（Single Instruction Multiple Data）可以实现数据级并行优化，如下图所示。  

![image-20230904155337640](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/5-simd-dapa-parallel.png?raw=true)

**尾端**  
LA的SIMD指令采用小尾端，数据在内存中从低位地址向高位地址依次存储。

**浮点数运算**  
向量浮点元素的运算处理规则和基础浮点数指令中完全一致。

**原子性**  
对于单线程来说，绝大多数情况下，无论地址是否对齐，单条向量访存指令的访存总是原子的。

### 2.1 SIMD编程实践

**两种主要方法：intrinsics VS asm**  
* intrinsics   ：使用编译器提供的C风格的接口编写C代码，易上手，易调试，可读性强，加速比略低。  
* asm          ：需要熟悉底层架构、汇编器语法，代码的可读性差，但是优化更加灵活，加速比更好。  
* 自动向量化：编译器也支持自动向量化，但加速比不及人工优化，可以作为补充。  

![image-20230904155421364](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/6-intrinsic-asm.png?raw=true)

**绝对误差和SAD**  
在数字图像处理中，用原始图像块与比较块之间的绝对误差和SAD(Sum of Absolute Difference)度量图像块之间相似度。绝对误差和可以用于各种目的，例如对象识别，立体图像的视差图的生成以及用于视频压缩的运动估计等。以下为X264中关于SAD实现：

![image-20230904155457038](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/7-sad.png?raw=true)

**深度神经网络中的relu函数**  

    void trae_relu_c(Float32 *x, int32_t len)
    {
        int32_t i;
    
        for (i = 0; i < len; i++)
        {
            x[i] = fmax(x[i], 0);
        }
    }

![image-20230904160716423](https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/8-relu.png?raw=true)

优化前后性能提升比例达到15倍。

| **数据大小** | C版本（us） | **LA**向量指令优化(us) | **提升比例** |
| ------------ | ----------- | ---------------------- | ------------ |
| 10000        | 54          | 6                      | 900%         |
| 100000       | 574         | 36                     | 1494%        |
| 100004       | 582         | 36                     | 1517%        |
| 100007       | 598         | 36                     | 1561%        |

## 3. 流水线优化

首先了解一下最经典的五级流水线，流水线处理器处理一条指令分为五个阶段，分别是取指，译码，执行，放存，写回。我们可以将处理器执行指令时的指令-时钟周期的对照图画出来，如图3.1所示，这种图被称为处理器执行的时空图，也被称为流水线图。画出流水线图是分析处理器行为的直观、有效的方法。

| 时钟周期数          | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    |
|---------------------|------|------|------|------|------|------|------|------|
| add.w $r2, $r1, $r1 | 取指 | 译码 | 执行 | 访存 | 写回 |      |      |      |
| add.w $r3, $r6, $r6 |      | 取指 | 译码 | 执行 | 访存 | 写回 |      |      |
| ld.w $r4, $r7, 0    |      |      | 取指 | 译码 | 执行 | 访存 | 写回 | 阻塞 |
| add.w %r5, %r8, %r8 |      |      |      | 取指 | 译码 | 执行 | 访存 | 写回 |
图3.1 流水线处理器的流水线时空图

从图3.1中可以看出，取指部件完成第一条指令后，就移交给译码部件，无需考虑该指令是否完成，继续下一条指令的取指操作。五个部件就像是五个工人合作的加工厂，每个工人做完自己的部分，将自己手头的工作交给下一个工人，并取得一个新的工作。这样每个工人都能一直处于工作状态。这种方式就叫做流水线。

图3.1所示的简单指令序列可以很顺畅的运行，每个时钟周期都能执行完一条指令，但是程序汇总的指令序列会比较复杂，通常存在指令间的相关，这就有可能导致流水线处理器执行出错。比如对于”add.w $r2, $r1, $r1; add.w $r3, $r2, $r2“这个指令序列，第一条指令讲结果写入r2寄存器，第2条指令在用r2寄存器的值进行计算。

从图3.1可以看出，第一条指令在第五级写回阶段才把结果写回到寄存器，第2条指令在第二级译码阶段（此时第一条指令尚在第3级执行阶段）就已经在读寄存器的值了。所以第2条指令读的是r2寄存器的旧值，从而造成了运算结果错误。
指令间的相关可以分为三类，数据相关，控制相关和结构相关。程序中，如果两条指令访问同一寄存器或内存单元，而且这两条指令中至少有1条是写该寄存器或内存单元的指令，那么这两条指令之间就存在数据相关。如果两条指令中一条是转移指令且另一条指令是否被执行取决于该转移指令的执行结果，则这两条指令之间存在控制相关。如果两条指令使用同一份硬件资源，则这两条指令之间存在结构相关。上面举得例子就属于数据相关，数据相关可以分为3种。第一种是写后读相关，即后面指令要用到前面指令所写的数据，也称为真相关。第二种是写后写相关，即两条指令写同一个单元，也称为输出相关。第三种是写后读相关，即后面的指令覆盖前面指令所读的单元，也称为反相关。

可以使用阻塞的方法来解决上述数据相关，如下图3.2所示。

| 时钟周期数          | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   |
|---------------------|------|------|------|------|------|------|------|------|------|------|------|
| add.w $r2, $r1, $r1 | 取指 | 译码 | 执行 | 访存 | 写回 |      |      |      |      |      |      |
| add.w $r3, $r2, $r2 |      | 取指 | 阻塞 | 阻塞 | 阻塞 | 译码 | 执行 | 访存 | 写回 |      |      |
| ld.w $r4, $r3, 0    |      |      | 阻塞 | 阻塞 | 阻塞 | 取指 | 阻塞 | 阻塞 | 阻塞 | 译码 | 执行 |
| add.w %r5, %r4, %r4 |      |      |      |      |      |      | 阻塞 | 阻塞 | 阻塞 | 取指 | 译码 |

图3.2 用阻塞解决数据相关的流水线时空图

阻塞功能在处理器种的实现就是讲被阻塞流水级所在的寄存器保持原值不变，同时向被阻塞流水级的下一级流水级输入指令无效信号，用流水线空泡填充。从图3.2可以看出这种情况使得流水线的执行效率大大降低，当然还有很多硬件解决的方法，比如流水线前递技术，比如鲲鹏920采用八级流水线结构，龙芯有9级，12级以及动态流水线的设计。但是在实际程序中，可以通过巧妙调整指令序列，来减少阻塞，提升性能。比如在LSOM项目中，有下面一段代码。

```
.macro LSX_MADD_COMPLEX16 in0, in1, in2, out, tmp0, tmp1, tmp2
    vxor.v    \tmp1,   \tmp1,  \tmp1
    vpackev.d \tmp0,   \in0,   \in0
    vfsub.d   \tmp1,   \tmp1,  \in0
    vpackod.d \tmp1,   \in0,   \tmp1
    vpackod.d \tmp2,   \in1,   \in1
    vpackev.d \tmp2,   \in1,   \tmp2
    vfmadd.d  \out,    \tmp0,  \in1,  \in2
    vfmadd.d  \out,    \tmp1,  \tmp2, \out
.endm
```
上面的代码段种，连续用到两条乘加指令且后一条乘加指令用到上一条的结果，而浮点乘加指令周期较长，这大大影响了性能。注意到从vapckev.d \tmp0, \in0, \in0这条指令后，tmp0, in1, in2的数据就没有修改过，因此可以讲vfmadd.d \out, \tmp0, \in1, \in2 这条指令一到vfsub.d \tmp1,  \tmp1, \in0这条指令后面执行。

修改之后的结果如下：

| 函数       | 改动前 (us) | 改动后 (us) |
|------------|-------------|-------------|
| corr1d_g_s | 7572936     | 5033058     |
| corr1d_x_s | 5090524     | 5033339     |
| corr1d_g_d | 10257037    | 10027204    |
| corr1d_x_d | 10538155    | 10026674    |
| corr1d_g_c | 20306796    | 19581821    |
| corr1d_x_c | 20840882    | 19584540    |
| corr1d_g_z | 47322634    | 35903545    |
| corr1d_x_z | 47468170    | 35444422    |

可以看出只是简单的调整一下指令的顺序，就能带来不俗的性能提升。
## 4. 访存优化

访存优化，访问的包括存储器中的数据和指令。本小结主要介绍对数据和指令访问的优化。

### 4.1 局部性

一个编写良好的计算机程序常常具有良好的局部性。它们倾向于引用邻近于其它最近引用过的数据项的数据项，或者最近引用过的数据项本身。这种倾向性被称为局部性原理。

局部性原理通常有两种不同的形式：**时间局部性**和**空间局部性**。时间局部性指的是被引用过一次的内存位置很可能在不远的将来在被多次引用，空间局部性指一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。

在硬件层面，局部性原理允许计算机的设计者引入高速缓存存储器来保存最近引用的指令和数据项，从而提高对主存的访问速度；在操作系统级，局部性原理允许系统使用主存作为虚拟地址空间最近被引用的块的高速缓存。

#### 4.1.1 对数据引用的局部性

```c
int sumvec (int v[N])
{
    int i, sum = 0;
    for (int i = 0; i < N; i++)
        sum += v[i];
    return sum;
}
```

在以上示例中，变量`sum`在每次循环迭代中被引用一次，因此对于`sum`来说，有好的时间局部性。另一方面，因为`sum`是标量，对于`sum`来说，没有空间局部性。向量`v`是被顺序读取，一个接一个，按照它们在内存中的顺序。因此对于变量`V`具有良好的空间局部性，但是时间局部性很差，因为每个向量元素指被访问一次。因为对于循环体中的每个变量，这个函数要么有好的空间局部性，要么有好的时间局部性，所以函数`sumvec`有良好的局部性。

#### 4.1.2 取指令的局部性

代码区别于数据的一个重要属性是运行时它是不能被修改的。当程序正在运行时，`CPU`只能从内存中读出它的指令，`CPU`很少会重写或修改这些指令。

以`4.1.1`中代码为例，`for`循环体中的指令是按照连续的内存执行的，因此循环具有良好的空间局部性。因为循环体会被执行多次，所以它也有很好的时间局部性。

#### 4.1.3 小结

- 重复引用相同变量的程序有良好的时间局部性
- 对于具有步长为`K`的引用模式的程序，步长越小，空间局部性越好。
- 对于取指令来说，循环有好的空间和时间局部性。循环体越小，循环迭代的次数越多，局部性越好。

### 4.2 存储器层次结构

<img src="https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/9-mem-access.png" alt="image-20230905114838969" style="zoom:67%;" />

**从高层往底层走，存储设备变得更慢，更便宜和更大。**

#### 4.2.1 缓存

高速缓存是一个小而快速的存储设备，它作为存储在更大、也更慢的设备中的数据对象的缓存区域。位于`k`层的更快更小的存储设备作为位于`k+1`层的更大更慢存储设备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层的数据对象。

数据总是以块大小为传送单位在第`k`和`k+1`层之间来回复制。虽然层次结构中任何一对相邻的层次之间块大小是固定的，但是其它的层次对之间可以有不同的块大小。例如，`L1`和`L0`之间的传送通常使用的是一个字节大小的块。`L2`和`L1`（以及`L3`和`L2`、`L4`和`L3`）之间传送的都是几十个字节的块。`L5`和`L4`之间的传送用的是大小为几百或几千字节的块。

#### 4.2.2 高速缓存

<img src="https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/10-mem-access.png" alt="image-20230905143809443" style="zoom:67%;" />

早期计算机的存储层次结构只有三层：`CPU`寄存器，`DRAM`主存储器和磁盘存储。不过由于`CPU`和主存之间逐渐增大的差距，系统设计者被迫在`CPU`和主存之间插入一个小的`SRAM`高速缓存存储器，称之为`L1`高速缓存。随着`CPU`和主存之间的性能差距不断增大，又先后插入`L2`和`L3`级缓存。

#### 4.2.3 通用的高速缓存存储器结构

假设一个计算机系统，存储器地址有`m`位，形成$M=2^m$个不同的地址。

高速缓存被组织为$S=2^s$个高速缓存组的数组；每个组包含`E`个高速缓存行；每个行由一个$B=2^b$字节的数据块组成，一个有效位指明这个行是否包含有意义的信息，还有$t=m-(b+s)$个标记位（是当前块的内存地址位的一个子集），它们唯一标识存储在这个高速缓存行中的块。

<img src="https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/11-mem-access.png" alt="image-20230905145443603" style="zoom:67%;" />

一般来说高速缓存的结构可以使用元组(S, E, B, m)来描述。高速缓存的大小`C`指的是所有块大小的和。标记位和有效位不包括在内。因此，$C=S\times E\times B$。

对于地址`A`，参数`S`和`B`将地址位分成三段，`A`中的`s`个组索引位是一个到`S`个组的数组索引。第一个组是0，第二个组是`1`，依次类推。组索引位被解释成一个无符号的整数，告诉我们这个字必须存储在哪个组中。一旦我们知道这个字必须放在哪个组中，`A`中的`t`个标记位就会告诉我们该组中的哪一行包含这个字。当且仅当设置了有效位并且该行的标记位与地址`A`中的标记位相匹配时，组中的这一行才包含这个字。最后由`A`中的`b`个块偏移位给出在`B`个字节的数据块中的字偏移。

如果`CPU`请求的字不再组中的任何一行，那么缓存就是不命中，高速缓存必须从内存中取出包含这个字的块。如果该组中没有空行，必须选择一个非空行进行替换。最简单的替换策略是随机选择要替换的行（`3A5000`中采用的应该就是随机替换策略），所以很难去利用高速缓存的替换策略。

#### 4.2.4 `3A5000`高速缓存存储结构剖析

龙芯`3A5000`每个`CPU`芯片有四个核，每个核有自己私有的`L1 i-cache`、`L1 d-cache`和`L2`统一高速缓存。所有核共享片上`L3`统一高速缓存。

<img src="https://github.com/yinshiyou/lsmedia/blob/main/img/01-%E9%BE%99%E8%8A%AFLA%E6%9E%B6%E6%9E%84%E7%BC%96%E7%A8%8B%E4%BC%98%E5%8C%96%E6%89%8B%E5%86%8C/12-mem-access.png" alt="image-20230905163615993" style="zoom:50%;" />

| 高速缓存类型   | 访问周期 | 高速缓存大小(C) | 相联度(E) | 块大小(B) | 组数(S) |
| -------------- | -------- | --------------- | --------- | --------- | ------- |
| L1 i-cache     | 4        | 64KB            | 4         | 64B       | 256     |
| L1 d-cache     | 4        | 64KB            | 4         | 64B       | 256     |
| L2统一高速缓存 | 10       | 256KB           | 16        | 64B       | 256     |
| L3统一高速缓存 | 40～70   | 16MB            | 16        | 64B       | 16384   |

### 4.3 编写高速缓存友好代码
